{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-dependent models and gate set tomography\n",
    "This tutorial demonstrates how time dependence can be added to models in pyGSTi and, since gate set tomography (GST) just optimizes model parameters, how to run time-dependent GST.  \n",
    "\n",
    "<font style=\"color:red\">**Notice: this topic describes \"beta level\" functionality in pyGSTi!**  It may contain bugs and holes in its implementation, which will be addressed in future releases.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsti\n",
    "from pygsti.modelpacks import smq1Q_XYI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent models\n",
    "To make a time-dependent `Model`, you create a time dependent gate or operation and add this to any of the models in pyGSTi.  (**Expert note**: this isn't quite true - currently, only models with `sim_type=\"map\"` support time-dependent evaluation of circuit outcomes, so we're currently limited to using this simulation type.)  Here's an example of how to make a custom idle operation that depolarizes its input state more and more over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimeDependentIdle(pygsti.modelmembers.operations.DenseOperator):\n",
    "    \"\"\"And idle that depolarizes over time with a parameterized rate\"\"\"\n",
    "    def __init__(self, initial_depol_rate):\n",
    "        #initialize with no noise\n",
    "        super(MyTimeDependentIdle,self).__init__(np.identity(4,'d'), \"densitymx\") # this is *super*-operator, so \"densitymx\"\n",
    "        self.from_vector([initial_depol_rate]) \n",
    "        self.set_time(0.0)\n",
    "    \n",
    "    @property\n",
    "    def num_params(self): \n",
    "        return 1 # we have two parameters\n",
    "    \n",
    "    def to_vector(self):\n",
    "        return np.array([self.depol_rate],'d') #our parameter vector\n",
    "        \n",
    "    def from_vector(self, v, close=False, dirty_value=True):\n",
    "        #initialize from parameter vector v\n",
    "        self.depol_rate = v[0]\n",
    "        self.dirty = dirty_value # mark that paramvec (self.to_vector()) may have changed\n",
    "        \n",
    "    def set_time(self,t):\n",
    "        a = 1.0-min(self.depol_rate*t,1.0)\n",
    "        \n",
    "        # ._ptr is a member of DenseOperator and is a reference to a\n",
    "        # numpy array that is the dense Pauli transfer matrix of this operator\n",
    "        # Technical note: use [:,:] here b/c we don't want to change id of self.base\n",
    "        self._ptr[:,:] = np.array([[1,   0,   0,   0],\n",
    "                                   [0,   a,   0,   0],\n",
    "                                   [0,   0,   a,   0],\n",
    "                                   [0,   0,   0,   a]],'d')\n",
    "        \n",
    "    def transform(self, S):\n",
    "        # Update self with inverse(S) * self * S (used in gauge optimization)\n",
    "        raise NotImplementedError(\"MyTimeDependentIdle cannot be transformed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key piece to note in the above class is the `set_time` method, which will be called sometime after `from_vector` and takes over responsiblility (from `from_vector`) for setting the object's `.base` member to the process matrix based on the parameters (in `from_vector`'s `v` *and* the time given to `set_time`). \n",
    "\n",
    "Here's an example of how to see what a `MyTimeDependentIdle(1.0)` gate looks like at the time 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0. ]\n",
      " [0.  0.9 0.  0. ]\n",
      " [0.  0.  0.9 0. ]\n",
      " [0.  0.  0.  0.9]]\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "Gi_at_t = MyTimeDependentIdle(1.0)\n",
    "Gi_at_t.set_time(t)\n",
    "Gi_matrix_at_t = Gi_at_t.to_dense()\n",
    "print(Gi_matrix_at_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a `MyTimeDependentIdle` gate to a model just like any other operator (in pyGSTi all operators are considered potentially time-dependent, and so the base class of our idle gate is `DenseOperator` just as it would be if we were creating a custom time-independent gate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = smq1Q_XYI.target_model(simulator=\"map\")\n",
    "mdl['Gi'] = MyTimeDependentIdle(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it - `mdl` is a time-dependent model, where `Gi` depolarizes with strength equal to the current time.  To compute the probability of a circuit, *GiGi* for example, we just call the usual `probs` function but specify a `time` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.9050000000000002), (('1',), 0.09499999999999997)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probabilities( ('Gi','Gi'), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero probability is equal to `0.5 * (1 + 0.9**2) = 0.905`, where the `0.9` comes from the Gi gate depolarization rate of 0.1 at time 0.1.  Note that this is the same as what you'd get using the `Gi_matrix_at_t` above (since our \"t\" was 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.905]]\n"
     ]
    }
   ],
   "source": [
    "E = mdl['Mdefault']['0']\n",
    "rho = mdl['rho0']\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t, np.dot(Gi_matrix_at_t, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent (or \"time aware\") circuits\n",
    "`Circuit` objects may include time information: labels within a circuit (e.g. `\"Gi\"`) may contain a *relative* time giving the duration of the operation being labeled.  By default, all labels have zero duration, meaning all the operations within the circuit are interpreted as occurring at the same time.  The below example gives the `Gi` gate a duration of 0.1, so that in the circuit simulation the first `Gi` occurs at time 0.1 and the second at 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gi_with_duration = pygsti.baseobjs.Label('Gi',time=0.1)\n",
    "mdl.probabilities( (Gi_with_duration, Gi_with_duration), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86]]\n"
     ]
    }
   ],
   "source": [
    "Gi_at_t.set_time(0.1)\n",
    "Gi_matrix_at_t1 = Gi_at_t.to_dense().copy()  # .copy() is needed because copies of the internal dense rep are not made by default (for performance)\n",
    "Gi_at_t.set_time(0.2)\n",
    "Gi_matrix_at_t2 = Gi_at_t.to_dense().copy()\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t2, np.dot(Gi_matrix_at_t1, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following \"!\"-shorthand (exclamation point followed by time) notation to specify label durations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probabilities( (('Gi','!0.1'),('Gi','!0.1')), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent data\n",
    "When `DataSet` objects contain timestamped data, these timestamps indicate at what *absolute* time the relevant circuit began executing when it produced certain data.  These time values correspond to those given to the `time` argument of `probs` above.\n",
    "\n",
    "At first, we don't bother with \"time-aware\" circuits, and just create a list of two sample circuits.  We then use the `times` argument of `generate_fake_data` to construct a `DataSet` with 100 samples of data taken at each of three times: 0, 0.1, and 0.2 (arbitrary time units).  By setting `sample_error=\"none\"` we can see the underlying outcome probabilities in the data (and how the depolarization caused by `Gi` increases with time): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "GiGi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.    0.   90.5   9.5  82.   18. ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.circuits.to_circuits([ ('Gi',), ('Gi','Gi')]) # just pick some circuits\n",
    "\n",
    "ds = pygsti.data.simulate_data(mdl, circuits, num_samples=100,\n",
    "                                       sample_error='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSet` with timestamps displays 3 parallel arrays for each circuit: \"Outcome Label Indices\", \"Time stamps\", and \"Repetitions\".  Each index corresponds to a bin of some number (given by \"Repetitions\") of X-outcomes (X given by \"Outcome Label Indices\") occuring at some time (given by \"Time stamps\").  We see that for each of the two circuits there are bins of 0- and 1-outcomes at each of times 0, 0.1, and 0.2.  Summing the bin counts (outcome repetitions) at each time, for a given circuit, gives 100.\n",
    "\n",
    "We can also add a duration of 0.05 time units to each `\"Gi\"` gate.  This makes the depolarization of the length-2 sequence a bit worse because the second application of `\"Gi\"` occurs at a time 0.05 units after the start of the circuit, at which point the noise on the gate as increased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "Gi!0.05Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [97.5   2.5  88.25 11.75 80.   20.  ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.circuits.to_circuits([ (('Gi','!0.05'),), (('Gi','!0.05'),('Gi','!0.05'))])\n",
    "\n",
    "ds = pygsti.data.simulate_data(mdl, circuits, num_samples=100,\n",
    "                                       sample_error='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent gate set tomography (TD-GST)\n",
    "To run gate set tomography, we'll need more sequences than the two in the example above.  We'll generate some timestamped data for the standard set of GST sequences for a 1-qubit $X(\\pi/2)$, $Y(\\pi/2)$, $I$ gate set.  In particular, we create a data-generating model that has a `MyTimeDependentIdle` idle gate (labeled by the empty-tuple) with a depolarization \"acceleration\" rate of 1.0, and we generate 10 counts at each of 10 equally spaced times between 0 and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_fiducials, meas_fiducials = smq1Q_XYI.prep_fiducials(), smq1Q_XYI.meas_fiducials()\n",
    "germs = smq1Q_XYI.germs()\n",
    "maxLengths = [1, 2]\n",
    "idle_gate_label = () # the smq1Q_XYI model labels an idle circuit layer by an empty tuple, not 'Gi'\n",
    "\n",
    "mdl_datagen = smq1Q_XYI.target_model(simulator=\"map\").depolarize(op_noise=0.01, spam_noise=0.001)\n",
    "mdl_datagen[idle_gate_label] = MyTimeDependentIdle(1.0)\n",
    "mdl_datagen.num_params\n",
    "\n",
    "edesign = pygsti.protocols.StandardGSTDesign(smq1Q_XYI.target_model(), prep_fiducials,\n",
    "                                             meas_fiducials, germs, maxLengths)\n",
    "\n",
    "#Data for initial non-sparse mode\n",
    "ds = pygsti.data.simulate_data(mdl_datagen, edesign.all_circuits_needing_data, num_samples=10,\n",
    "                                       sample_error=\"binomial\", seed=1234, times=np.linspace(0,0.3,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run GST on this timestamped data similar to any other data, using the `GateSetTomography` protocol.  The key difference is that a `TimeDependentPoissonPicLogLFunction` objective function is used, which evaluates the log-likelihood by accounting separately for each timestamp.  It takes the timestamps in the given `DataSet` seriously, and performs time-dependent circuit simulations rather than aggregating the counts across all times (the behavior when the default objective function is used).\n",
    "\n",
    "Running time-dependent GST with 10 timesteps requires 10 times the number of circuit simulations (each circuit needs to be simulated 10 times).  This, coupled with the fact that this the time-dependent simulation routines are less optimized in pyGSTi, means this running time-dependent GST is significantly slower than normal GST.  Note also that we set `gauge_opt_suite=None`.  This disables gauge optimization, and this is necessary since it won't work because our `MyTimeDependentIdle` operation doesn't implement `transform` (the action of a gauge transformation).\n",
    "\n",
    "The cell below will take around 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iterative GST: Iter 1 of 2  92 circuits ---: \n",
      "  MapLayout: 1 processors divided into 1 x 1 (= 1) grid along circuit and parameter directions.\n",
      "     8 atoms, parameter block size limits (None,)\n",
      "  *** Distributing 8 atoms to 1 atom-processing groups (1 cores) ***\n",
      "      More atom-processors than hosts: each host gets ~1 atom-processors\n",
      "      Atom-processors already occupy a single node, dividing atom-processor into 1 param-processors.\n",
      "  *** Divided 1-host atom-processor (~1 procs) into 1 param-processing groups ***\n",
      "  --- TimeDependentPoissonPicLogLFunction GST ---\n",
      "    --- Outer Iter 0: norm_f = 1458.18, mu=1, |x|=2.73861, |J|=84056.2\n",
      "        - Inner Loop: mu=1124.47, norm_dx=1.9721e-06\n",
      "            (cont): norm_new_f=955.035, dL=1112.02, dF=503.146, reldL=0.76261, reldF=0.34505\n",
      "            Accepted! gain ratio=0.45246  mu * 1.00086 => 1125.43\n",
      "    --- Outer Iter 1: norm_f = 955.035, mu=1125.43, |x|=2.73835, |J|=7225.64\n",
      "        - Inner Loop: mu=1125.43, norm_dx=2.69373e-05\n",
      "            (cont): norm_new_f=661.566, dL=562.014, dF=293.469, reldL=0.588474, reldF=0.307286\n",
      "            Accepted! gain ratio=0.522174  mu * 0.999913 => 1125.33\n",
      "    --- Outer Iter 2: norm_f = 661.566, mu=1125.33, |x|=2.73558, |J|=1001.04\n",
      "        - Inner Loop: mu=1125.33, norm_dx=5.33771e-05\n",
      "            (cont): norm_new_f=566.428, dL=86.3841, dF=95.1383, reldL=0.130575, reldF=0.143808\n",
      "            Accepted! gain ratio=1.10134  mu * 0.333333 => 375.112\n",
      "    --- Outer Iter 3: norm_f = 566.428, mu=375.112, |x|=2.73022, |J|=444.971\n",
      "        - Inner Loop: mu=375.112, norm_dx=7.31707e-05\n",
      "            (cont): norm_new_f=529.189, dL=28.5485, dF=37.2394, reldL=0.050401, reldF=0.0657443\n",
      "            Accepted! gain ratio=1.30442  mu * 0.333333 => 125.037\n",
      "    --- Outer Iter 4: norm_f = 529.189, mu=125.037, |x|=2.72427, |J|=293.492\n",
      "        - Inner Loop: mu=125.037, norm_dx=0.000237012\n",
      "            (cont): norm_new_f=511.029, dL=14.3748, dF=18.16, reldL=0.0271638, reldF=0.0343167\n",
      "            Accepted! gain ratio=1.26332  mu * 0.333333 => 41.6791\n",
      "    --- Outer Iter 5: norm_f = 511.029, mu=41.6791, |x|=2.72056, |J|=222.035\n",
      "        - Inner Loop: mu=41.6791, norm_dx=0.00153776\n",
      "            (cont): norm_new_f=500.647, dL=7.5181, dF=10.3821, reldL=0.0147117, reldF=0.0203161\n",
      "            Accepted! gain ratio=1.38095  mu * 0.333333 => 13.893\n",
      "    --- Outer Iter 6: norm_f = 500.647, mu=13.893, |x|=2.7233, |J|=191.349\n",
      "        - Inner Loop: mu=13.893, norm_dx=0.0114902\n",
      "            (cont): norm_new_f=485.583, dL=10.3765, dF=15.0639, reldL=0.0207262, reldF=0.0300889\n",
      "            Accepted! gain ratio=1.45173  mu * 0.333333 => 4.63101\n",
      "    --- Outer Iter 7: norm_f = 485.583, mu=4.63101, |x|=2.74585, |J|=194.052\n",
      "        - Inner Loop: mu=4.63101, norm_dx=0.0783395\n",
      "            (cont): norm_new_f=34647.4, dL=19.575, dF=-34161.8, reldL=0.0403124, reldF=-70.3522\n",
      "            Rejected!  mu => mu*nu = 9.26201, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=9.26201, norm_dx=0.0232952\n",
      "            (cont): norm_new_f=478.799, dL=11.0713, dF=6.78382, reldL=0.0227999, reldF=0.0139705\n",
      "            Accepted! gain ratio=0.612742  mu * 0.988536 => 9.15583\n",
      "    --- Outer Iter 8: norm_f = 478.799, mu=9.15583, |x|=2.76718, |J|=323.136\n",
      "        - Inner Loop: mu=9.15583, norm_dx=0.0465102\n",
      "            (cont): norm_new_f=178008, dL=22.7312, dF=-177529, reldL=0.0474754, reldF=-370.781\n",
      "            Rejected!  mu => mu*nu = 18.3117, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=18.3117, norm_dx=0.0129981\n",
      "            (cont): norm_new_f=4998.3, dL=13.9309, dF=-4519.5, reldL=0.0290956, reldF=-9.43924\n",
      "            Rejected!  mu => mu*nu = 73.2466, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=73.2466, norm_dx=0.00090058\n",
      "            (cont): norm_new_f=473.074, dL=5.01559, dF=5.72526, reldL=0.0104754, reldF=0.0119575\n",
      "            Accepted! gain ratio=1.14149  mu * 0.333333 => 24.4155\n",
      "    --- Outer Iter 9: norm_f = 473.074, mu=24.4155, |x|=2.77016, |J|=166.923\n",
      "        - Inner Loop: mu=24.4155, norm_dx=0.00743675\n",
      "            (cont): norm_new_f=2440.1, dL=5.67125, dF=-1967.02, reldL=0.0119881, reldF=-4.15796\n",
      "            Rejected!  mu => mu*nu = 48.8311, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=48.8311, norm_dx=0.00191685\n",
      "            (cont): norm_new_f=469.522, dL=2.99018, dF=3.5521, reldL=0.00632075, reldF=0.00750856\n",
      "            Accepted! gain ratio=1.18792  mu * 0.333333 => 16.277\n",
      "    --- Outer Iter 10: norm_f = 469.522, mu=16.277, |x|=2.77738, |J|=259.807\n",
      "        - Inner Loop: mu=16.277, norm_dx=0.0113378\n",
      "            (cont): norm_new_f=464.875, dL=6.02221, dF=4.64664, reldL=0.0128263, reldF=0.00989654\n",
      "            Accepted! gain ratio=0.771583  mu * 0.83975 => 13.6686\n",
      "    --- Outer Iter 11: norm_f = 464.875, mu=13.6686, |x|=2.78525, |J|=148.36\n",
      "        - Inner Loop: mu=13.6686, norm_dx=0.0328442\n",
      "            (cont): norm_new_f=244473, dL=13.0343, dF=-244008, reldL=0.0280383, reldF=-524.891\n",
      "            Rejected!  mu => mu*nu = 27.3373, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=27.3373, norm_dx=0.00858569\n",
      "            (cont): norm_new_f=23332.6, dL=7.74664, dF=-22867.7, reldL=0.0166639, reldF=-49.1911\n",
      "            Rejected!  mu => mu*nu = 109.349, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=109.349, norm_dx=0.000551847\n",
      "            (cont): norm_new_f=461.551, dL=2.30915, dF=3.32417, reldL=0.00496725, reldF=0.00715067\n",
      "            Accepted! gain ratio=1.43956  mu * 0.333333 => 36.4497\n",
      "    --- Outer Iter 12: norm_f = 461.551, mu=36.4497, |x|=2.79161, |J|=182.719\n",
      "        - Inner Loop: mu=36.4497, norm_dx=0.0039277\n",
      "            (cont): norm_new_f=457.865, dL=2.12057, dF=3.68568, reldL=0.00459445, reldF=0.00798543\n",
      "            Accepted! gain ratio=1.73806  mu * 0.333333 => 12.1499\n",
      "    --- Outer Iter 13: norm_f = 457.865, mu=12.1499, |x|=2.80061, |J|=198.465\n",
      "        - Inner Loop: mu=12.1499, norm_dx=0.0334078\n",
      "            (cont): norm_new_f=450.232, dL=5.17264, dF=7.63353, reldL=0.0112973, reldF=0.016672\n",
      "            Accepted! gain ratio=1.47575  mu * 0.333333 => 4.04997\n",
      "    --- Outer Iter 14: norm_f = 450.232, mu=4.04997, |x|=2.83209, |J|=171.74\n",
      "        - Inner Loop: mu=4.04997, norm_dx=0.290438\n",
      "            (cont): norm_new_f=1893.99, dL=14.5476, dF=-1443.76, reldL=0.0323114, reldF=-3.2067\n",
      "            Rejected!  mu => mu*nu = 8.09993, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=8.09993, norm_dx=0.0879678\n",
      "            (cont): norm_new_f=448.33, dL=9.04528, dF=1.90167, reldL=0.0200903, reldF=0.00422376\n",
      "            Accepted! gain ratio=0.210239  mu * 1.19463 => 9.67642\n",
      "    --- Outer Iter 15: norm_f = 448.33, mu=9.67642, |x|=2.90458, |J|=8574.87\n",
      "        - Inner Loop: mu=9.67642, norm_dx=0.02303\n",
      "            (cont): norm_new_f=444.372, dL=22.0586, dF=3.95811, reldL=0.0492017, reldF=0.00882857\n",
      "            Accepted! gain ratio=0.179436  mu * 1.26353 => 12.2265\n",
      "    --- Outer Iter 16: norm_f = 444.372, mu=12.2265, |x|=2.94607, |J|=705.284\n",
      "        - Inner Loop: mu=12.2265, norm_dx=0.0322346\n",
      "            (cont): norm_new_f=296349, dL=16.0989, dF=-295905, reldL=0.0362283, reldF=-665.894\n",
      "            Rejected!  mu => mu*nu = 24.4529, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=24.4529, norm_dx=0.00978452\n",
      "            (cont): norm_new_f=10600.3, dL=10.5225, dF=-10156, reldL=0.0236794, reldF=-22.8547\n",
      "            Rejected!  mu => mu*nu = 97.8118, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=97.8118, norm_dx=0.000746173\n",
      "            (cont): norm_new_f=439.847, dL=4.26127, dF=4.52447, reldL=0.00958944, reldF=0.0101817\n",
      "            Accepted! gain ratio=1.06177  mu * 0.333333 => 32.6039\n",
      "    --- Outer Iter 17: norm_f = 439.847, mu=32.6039, |x|=2.93873, |J|=288.633\n",
      "        - Inner Loop: mu=32.6039, norm_dx=0.00351243\n",
      "            (cont): norm_new_f=438.538, dL=2.91867, dF=1.30925, reldL=0.00663565, reldF=0.00297661\n",
      "            Accepted! gain ratio=0.448578  mu * 1.00109 => 32.6394\n",
      "    --- Outer Iter 18: norm_f = 438.538, mu=32.6394, |x|=2.9211, |J|=485.529\n",
      "        - Inner Loop: mu=32.6394, norm_dx=0.00058584\n",
      "            (cont): norm_new_f=438.074, dL=3.4284, dF=0.463991, reldL=0.0078178, reldF=0.00105804\n",
      "            Accepted! gain ratio=0.135337  mu * 1.38794 => 45.3015\n",
      "    --- Outer Iter 19: norm_f = 438.074, mu=45.3015, |x|=2.92222, |J|=258.822\n",
      "        - Inner Loop: mu=45.3015, norm_dx=0.000546536\n",
      "            (cont): norm_new_f=439.075, dL=1.91687, dF=-1.0013, reldL=0.00437567, reldF=-0.00228569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Rejected!  mu => mu*nu = 90.603, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=90.603, norm_dx=0.000145385\n",
      "            (cont): norm_new_f=436.835, dL=1.12942, dF=1.23873, reldL=0.00257814, reldF=0.00282768\n",
      "            Accepted! gain ratio=1.09679  mu * 0.333333 => 30.201\n",
      "    --- Outer Iter 20: norm_f = 436.835, mu=30.201, |x|=2.92054, |J|=429.558\n",
      "        - Inner Loop: mu=30.201, norm_dx=4.45742e-05\n",
      "            (cont): norm_new_f=436.239, dL=0.431137, dF=0.596581, reldL=0.000986956, reldF=0.00136569\n",
      "            Accepted! gain ratio=1.38374  mu * 0.333333 => 10.067\n",
      "    --- Outer Iter 21: norm_f = 436.239, mu=10.067, |x|=2.91928, |J|=349.196\n",
      "        - Inner Loop: mu=10.067, norm_dx=0.000682888\n",
      "            (cont): norm_new_f=435.975, dL=0.818716, dF=0.264003, reldL=0.00187676, reldF=0.000605181\n",
      "            Accepted! gain ratio=0.32246  mu * 1.04477 => 10.5177\n",
      "    --- Outer Iter 22: norm_f = 435.975, mu=10.5177, |x|=2.92534, |J|=435.845\n",
      "        - Inner Loop: mu=10.5177, norm_dx=0.000898795\n",
      "            (cont): norm_new_f=435.847, dL=2.37271, dF=0.127554, reldL=0.00544232, reldF=0.000292572\n",
      "            Accepted! gain ratio=0.0537587  mu * 1.71089 => 17.9946\n",
      "    --- Outer Iter 23: norm_f = 435.847, mu=17.9946, |x|=2.92379, |J|=428.934\n",
      "        - Inner Loop: mu=17.9946, norm_dx=0.00105633\n",
      "            (cont): norm_new_f=442.921, dL=3.47586, dF=-7.07379, reldL=0.00797496, reldF=-0.01623\n",
      "            Rejected!  mu => mu*nu = 35.9891, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=35.9891, norm_dx=0.000312188\n",
      "            (cont): norm_new_f=436.721, dL=2.53788, dF=-0.873596, reldL=0.00582286, reldF=-0.00200436\n",
      "            Rejected!  mu => mu*nu = 143.956, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=143.956, norm_dx=2.53241e-05\n",
      "            (cont): norm_new_f=434.887, dL=1.11898, dF=0.960581, reldL=0.00256737, reldF=0.00220394\n",
      "            Accepted! gain ratio=0.858443  mu * 0.631573 => 90.919\n",
      "    --- Outer Iter 24: norm_f = 434.887, mu=90.919, |x|=2.9242, |J|=415.858\n",
      "        - Inner Loop: mu=90.919, norm_dx=2.42007e-05\n",
      "            (cont): norm_new_f=434.748, dL=0.205253, dF=0.138147, reldL=0.00047197, reldF=0.000317662\n",
      "            Accepted! gain ratio=0.673057  mu * 0.958537 => 87.1493\n",
      "    --- Outer Iter 25: norm_f = 434.748, mu=87.1493, |x|=2.92524, |J|=2536.85\n",
      "        - Inner Loop: mu=87.1493, norm_dx=1.2651e-05\n",
      "            (cont): norm_new_f=434.56, dL=0.17853, dF=0.188766, reldL=0.00041065, reldF=0.000434195\n",
      "            Accepted! gain ratio=1.05734  mu * 0.333333 => 29.0498\n",
      "    --- Outer Iter 26: norm_f = 434.56, mu=29.0498, |x|=2.92581, |J|=266.762\n",
      "        - Inner Loop: mu=29.0498, norm_dx=6.69191e-05\n",
      "            (cont): norm_new_f=434.57, dL=0.144109, dF=-0.0107436, reldL=0.000331621, reldF=-2.47229e-05\n",
      "            Rejected!  mu => mu*nu = 58.0995, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=58.0995, norm_dx=1.72778e-05\n",
      "            (cont): norm_new_f=434.561, dL=0.0801229, dF=-0.00182705, reldL=0.000184377, reldF=-4.20437e-06\n",
      "            Rejected!  mu => mu*nu = 232.398, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=232.398, norm_dx=1.10779e-06\n",
      "            (cont): norm_new_f=434.556, dL=0.0226533, dF=0.00366581, reldL=5.21293e-05, reldF=8.4357e-06\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  _objfn = 869.119 (920 data params - 32 (approx) model params = expected mean of 888; p-value = 0.668359)\n",
      "  Completed in 85.3s\n",
      "  Iteration 1 took 85.3s\n",
      "  \n",
      "--- Iterative GST: Iter 2 of 2  168 circuits ---: \n",
      "  MapLayout: 1 processors divided into 1 x 1 (= 1) grid along circuit and parameter directions.\n",
      "     8 atoms, parameter block size limits (None,)\n",
      "  *** Distributing 8 atoms to 1 atom-processing groups (1 cores) ***\n",
      "      More atom-processors than hosts: each host gets ~1 atom-processors\n",
      "      Atom-processors already occupy a single node, dividing atom-processor into 1 param-processors.\n",
      "  *** Divided 1-host atom-processor (~1 procs) into 1 param-processing groups ***\n",
      "  --- TimeDependentPoissonPicLogLFunction GST ---\n",
      "    --- Outer Iter 0: norm_f = 878.891, mu=1, |x|=2.92581, |J|=329.268\n",
      "        - Inner Loop: mu=61.0707, norm_dx=0.000712977\n",
      "            (cont): norm_new_f=874.775, dL=4.13033, dF=4.11641, reldL=0.00469948, reldF=0.00468364\n",
      "            Accepted! gain ratio=0.996629  mu * 0.333333 => 20.3569\n",
      "    --- Outer Iter 1: norm_f = 874.775, mu=20.3569, |x|=2.91413, |J|=296.19\n",
      "        - Inner Loop: mu=20.3569, norm_dx=0.00486618\n",
      "            (cont): norm_new_f=1196.29, dL=5.60986, dF=-321.515, reldL=0.00641292, reldF=-0.367541\n",
      "            Rejected!  mu => mu*nu = 40.7138, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=40.7138, norm_dx=0.00130168\n",
      "            (cont): norm_new_f=957.225, dL=3.46012, dF=-82.4505, reldL=0.00395544, reldF=-0.0942534\n",
      "            Rejected!  mu => mu*nu = 162.855, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=162.855, norm_dx=8.80608e-05\n",
      "            (cont): norm_new_f=873.105, dL=1.16141, dF=1.67019, reldL=0.00132767, reldF=0.00190928\n",
      "            Accepted! gain ratio=1.43807  mu * 0.333333 => 54.2851\n",
      "    --- Outer Iter 2: norm_f = 873.105, mu=54.2851, |x|=2.9121, |J|=438.254\n",
      "        - Inner Loop: mu=54.2851, norm_dx=0.000470318\n",
      "            (cont): norm_new_f=871.547, dL=1.10892, dF=1.55741, reldL=0.00127008, reldF=0.00178376\n",
      "            Accepted! gain ratio=1.40444  mu * 0.333333 => 18.095\n",
      "    --- Outer Iter 3: norm_f = 871.547, mu=18.095, |x|=2.90423, |J|=2739.05\n",
      "        - Inner Loop: mu=18.095, norm_dx=0.00215868\n",
      "            (cont): norm_new_f=870.051, dL=1.29052, dF=1.49652, reldL=0.00148072, reldF=0.00171709\n",
      "            Accepted! gain ratio=1.15963  mu * 0.333333 => 6.03167\n",
      "    --- Outer Iter 4: norm_f = 870.051, mu=6.03167, |x|=2.8879, |J|=350.079\n",
      "        - Inner Loop: mu=6.03167, norm_dx=0.00206032\n",
      "            (cont): norm_new_f=870.039, dL=0.985235, dF=0.0113818, reldL=0.00113239, reldF=1.30817e-05\n",
      "            Accepted! gain ratio=0.0115523  mu * 1.93228 => 11.6549\n",
      "    --- Outer Iter 5: norm_f = 870.039, mu=11.6549, |x|=2.87641, |J|=2332.86\n",
      "        - Inner Loop: mu=11.6549, norm_dx=0.000616942\n",
      "            (cont): norm_new_f=869.94, dL=1.23917, dF=0.0989119, reldL=0.00142427, reldF=0.000113687\n",
      "            Accepted! gain ratio=0.0798212  mu * 1.59346 => 18.5716\n",
      "    --- Outer Iter 6: norm_f = 869.94, mu=18.5716, |x|=2.88201, |J|=833.556\n",
      "        - Inner Loop: mu=18.5716, norm_dx=0.000202206\n",
      "            (cont): norm_new_f=870.053, dL=1.21667, dF=-0.113062, reldL=0.00139857, reldF=-0.000129965\n",
      "            Rejected!  mu => mu*nu = 37.1431, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=37.1431, norm_dx=5.96138e-05\n",
      "            (cont): norm_new_f=869.548, dL=0.715785, dF=0.392613, reldL=0.000822798, reldF=0.00045131\n",
      "            Accepted! gain ratio=0.548507  mu * 0.999087 => 37.1092\n",
      "    --- Outer Iter 7: norm_f = 869.548, mu=37.1092, |x|=2.8822, |J|=2729.27\n",
      "        - Inner Loop: mu=37.1092, norm_dx=6.05114e-06\n",
      "            (cont): norm_new_f=869.368, dL=0.422818, dF=0.180069, reldL=0.00048625, reldF=0.000207083\n",
      "            Accepted! gain ratio=0.425878  mu * 1.00326 => 37.2301\n",
      "    --- Outer Iter 8: norm_f = 869.368, mu=37.2301, |x|=2.88154, |J|=324.173\n",
      "        - Inner Loop: mu=37.2301, norm_dx=1.31951e-05\n",
      "            (cont): norm_new_f=871.848, dL=0.257895, dF=-2.48018, reldL=0.000296646, reldF=-0.00285285\n",
      "            Rejected!  mu => mu*nu = 74.4602, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=74.4602, norm_dx=4.01172e-06\n",
      "            (cont): norm_new_f=870.972, dL=0.162577, dF=-1.60478, reldL=0.000187006, reldF=-0.00184591\n",
      "            Rejected!  mu => mu*nu = 297.841, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=297.841, norm_dx=3.23667e-07\n",
      "            (cont): norm_new_f=869.488, dL=0.0527304, dF=-0.120792, reldL=6.06537e-05, reldF=-0.000138942\n",
      "            Rejected!  mu => mu*nu = 2382.73, nu => 2*nu = 16\n",
      "        - Inner Loop: mu=2382.73, norm_dx=5.69499e-09\n",
      "            (cont): norm_new_f=869.356, dL=0.00731851, dF=0.0114015, reldL=8.4182e-06, reldF=1.31147e-05\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  _objfn = 1738.74 (1680 data params - 32 (approx) model params = expected mean of 1648; p-value = 0.0589193)\n",
      "  Completed in 51.3s\n",
      "  Iteration 2 took 51.4s\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Last iteration:\n",
      "  Final optimization took 0.0s\n",
      "  \n",
      "Iterative GST Total Time: 136.7s\n"
     ]
    }
   ],
   "source": [
    "target_model = smq1Q_XYI.target_model(\"full TP\", simulator=\"map\") # TP-constraints on the non-Gi gates\n",
    "target_model[idle_gate_label] = MyTimeDependentIdle(0.0)\n",
    "target_model.sim = pygsti.forwardsims.MapForwardSimulator(max_cache_size=0)\n",
    "\n",
    "builders = pygsti.protocols.GSTObjFnBuilders([pygsti.objectivefns.TimeDependentPoissonPicLogLFunction.builder()],[])\n",
    "custom_opt = {'tol': 1e-4, 'damping_mode': 'JTJ', 'damping_clip': (1.0, 1000.0)} # tweak optimizer parameters for better performance (expert-level)\n",
    "gst = pygsti.protocols.GateSetTomography(target_model, gaugeopt_suite=None,\n",
    "                                         objfn_builders=builders, optimizer=custom_opt, verbosity=4)\n",
    "data = pygsti.protocols.ProtocolData(edesign, ds)\n",
    "results = gst.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the (non-gauge-optimizeed) best-fit model from `results`, and see what depolarization \"acceleration\" was found.  We find that the value is reasonably close to the value of 1.0 that we used to generate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-dependent idle parameters =  [0.97808845]\n"
     ]
    }
   ],
   "source": [
    "final_mdl = results.estimates['GateSetTomography'].models['final iteration estimate']\n",
    "print(\"Time-dependent idle parameters = \",final_mdl[idle_gate_label].to_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function at data-generating model =  880.9619775626478\n",
      "Objective function at best-fit (GST) model (should be lower) =  869.36770116516\n"
     ]
    }
   ],
   "source": [
    "# Check that GST model fits the data *better* than the data-generating model\n",
    "builder = pygsti.objectivefns.TimeDependentPoissonPicLogLFunction.builder()\n",
    "objfn = builder.build(mdl_datagen, data.dataset, list(data.dataset.keys()))\n",
    "print(\"Objective function at data-generating model = \",objfn.fn())\n",
    "\n",
    "objfn2 = builder.build(final_mdl, data.dataset, list(data.dataset.keys()))\n",
    "print(\"Objective function at best-fit (GST) model (should be lower) = \",objfn2.fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
