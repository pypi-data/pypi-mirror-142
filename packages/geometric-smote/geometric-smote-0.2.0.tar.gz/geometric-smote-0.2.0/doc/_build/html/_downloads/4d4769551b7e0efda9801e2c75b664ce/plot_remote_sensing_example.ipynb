{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Remote sensing examples\n\nThe following examples make use of scikit-learn's Forest Cover Type dataset and\nthe Indian Pines dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Joao Fonseca <jpmrfonseca@gmail.com>\n#          Manvel Khudinyan <armkhudinyan@gmail.com>\n#          Georgios Douzas <gdouzas@icloud.com>\n# Licence: MIT\n\nfrom collections import Counter\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import fetch_openml, fetch_covtype\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, make_scorer, cohen_kappa_score\nfrom imblearn.metrics import classification_report_imbalanced\nfrom imblearn.pipeline import make_pipeline, Pipeline\n\nfrom gsmote import GeometricSMOTE\n\nprint(__doc__)\n\nRANDOM_STATE = 5\n\n\ndef print_class_counts(y):\n    \"\"\"Print the class counts.\"\"\"\n    counts = dict(Counter(y))\n    class_counts = pd.DataFrame(counts.values(), index=counts.keys(), columns=['Count']).sort_index()\n    print(class_counts)\n\n\ndef print_classification_report(clf, X_train, X_test, y_train, y_test):\n    \"\"\"Fit classifier and print classification report.\"\"\"\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    clf_name = clf.__class__.__name__\n    div = '=' * len(clf_name)\n    title = f'\\n{div}\\n{clf_name}\\n{div}\\n'\n    print(title, classification_report_imbalanced(y_test, y_pred))\n\n\ndef plot_confusion_matrix(cm, classes):\n    \"\"\"This function prints and plots the \n    normalized confusion matrix.\"\"\"\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], '.2f'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forest Cover Type\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The samples in this dataset correspond to 30\u00d730m patches of forest in the US,\ncollected for the task of predicting each patch's cover type, i.e. the\ndominant species of tree. There are seven covertypes, making this a multiclass\nclassification problem. Each sample has 54 features, described on the\n`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`_.\nSome of the features are boolean indicators, while others are discrete or\ncontinuous measurements.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n\n The function :func:`sklearn.datasets.fetch_covtype` will load dataset. It will\n be downloaded from the web if necessary. This dataset is clearly imbalanced.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = fetch_covtype(return_X_y=True)\nprint_class_counts(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification\n\n Below we use the Random Forest Classifier to predict the forest type of each\n patch of forest. Two experiments are ran: One using only the classifier and\n another that creates a pipeline of Geometric SMOTE and the classifier. A\n classification report is printed for both experiments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitted_data = train_test_split(X, y, test_size=0.95, random_state=RANDOM_STATE, shuffle=True)\n\nclf = RandomForestClassifier(bootstrap=True, n_estimators=10, random_state=RANDOM_STATE)\novs_clf = make_pipeline(GeometricSMOTE(random_state=RANDOM_STATE), clf)\n\nprint_classification_report(clf, *splitted_data)\nprint_classification_report(ovs_clf, *splitted_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indian Pines\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This hyperspectral data set has 220 spectral bands and 20 m spatial resolution. \nThe imagery was collected on 12 June 1992 and represents a 2.9 by 2.9 km area \nin Tippecanoe County, Indiana, USA. The area is agricultural and eight classes \nas land-use types are presented: alfalfa, corn, grass, hay, oats, soybeans, \ntrees, and wheat. The Indian Pines data set has been used for testing and \ncomparing algorithms. The number of samples varies greatly among the classes, \nwhich is known as an imbalanced training set. Data are made available by \nPurdue University (https://engineering.purdue.edu/~biehl/MultiSpec/hyperspectral.html).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n\n This dataset provides the data in numpay arrays. Predictor and target \n variables are already split (X and y accordingly). Predictor data consists \n of 220 features. Target attributes are the land cover classes. Dataset has \n 9144 samples.  \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y, *_ = fetch_openml('Indian_pines').values()\nprint_class_counts(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification \n\n Below we use the Geometric SMOTE oversampler and Decision Tree classifier,\n combined by a pipeline. GridSearchCV class from scikit-learn is used to find the\n best parameters of the oversampler.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitted_data = train_test_split(X, y, test_size=0.5, random_state=RANDOM_STATE, shuffle=True)\n\nparam_grid = {\n    'gsmote__deformation_factor': [0.25, 0.50, 0.75], \n    'gsmote__truncation_factor': [-0.5, 0.0, 0.5]\n}\nclf = DecisionTreeClassifier(random_state=RANDOM_STATE)\novs_clf = Pipeline([\n    ('gsmote', GeometricSMOTE(random_state=RANDOM_STATE)),\n    ('dt', DecisionTreeClassifier(random_state=RANDOM_STATE)),\n])\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\nscoring = make_scorer(cohen_kappa_score)\ngscv = GridSearchCV(ovs_clf, param_grid, scoring=scoring, refit=True, cv=cv, n_jobs=-1)\n\nprint_classification_report(clf, *splitted_data)\nprint_classification_report(gscv, *splitted_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion matrix\n\n To describe the performance of the classification models per classes you can \n create the normalized confusion matrix. Particularly, this matrix represented \n the predictive power of the classifier LR with G-SMOTE oversampler in \n the discrimination of eight classes using 220 Band AVIRIS Hyperspectral Image \n Data Set (Indian Pine Test Site 3). The values of the diagonal elements \n represented the degree of correctly predicted classes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, X_test, _, y_test = splitted_data\nconf_matrix = confusion_matrix(y_test, gscv.predict(X_test), labels = np.unique(y_test))\nplot_confusion_matrix(conf_matrix, classes=np.unique(y_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}