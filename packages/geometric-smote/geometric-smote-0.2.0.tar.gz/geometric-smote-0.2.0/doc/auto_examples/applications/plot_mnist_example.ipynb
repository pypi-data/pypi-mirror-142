{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MNIST Dataset oversampling\n\nThe example makes use of openml's MNIST dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Joao Fonseca <jpmrfonseca@gmail.com>\n#          Georgios Douzas <gdouzas@icloud.com>\n# Licence: MIT\n\nfrom random import choice\nfrom collections import Counter\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import GridSearchCV, train_test_split, PredefinedSplit\nfrom sklearn.linear_model import LogisticRegression\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.datasets import make_imbalance\nfrom imblearn.pipeline import Pipeline\n\nfrom gsmote import GeometricSMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST Dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The MNIST database is composed of handwritten digits with 784 features,\nthe raw data is available at: http://yann.lecun.com/exdb/mnist/.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is a subset of a larger set available from NIST. The digits have been\nsize-normalized and centered in a fixed-size image. It is a good database for\npeople who want to try learning techniques and pattern recognition methods on\nreal-world data while spending minimal efforts on preprocessing and\nformatting. The original black and white (bilevel) images from NIST were size\nnormalized to fit in a 20x20 pixel box while preserving their aspect ratio.\nThe resulting images contain grey levels as a result of the anti-aliasing\ntechnique used by the normalization algorithm. the images were centered in a\n28x28 image by computing the center of mass of the pixels, and translating\nthe image so as to position this point at the center of the 28x28 field.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function :func:`sklearn.datasets.fetch_openml` will load the MNIST\ndataset; it returns a tuple object with the feature matrix as the\nfirst item and the target values in the second. The dataset will be\ndownloaded from the web if necessary. Afterwards we select only 1's and 7's\nfrom the dataset, create a balanced hold-out set and use function\n:func:`imblearn.datasets.make_imbalance` imbalance the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_X, _y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\nselection = _y.isin([\"1\", \"7\"])\nX = _X[selection]\ny = _y[selection]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\nX_train, y_train = make_imbalance(\n    X=X_train,\n    y=y_train,\n    sampling_strategy={\"1\": 2, \"7\": int(Counter(y_train)[\"7\"] * 0.02)},\n)\n\n\nfor t, y_ in [(\"Train\", y_train), (\"Test\", y_test)]:\n    dist = Counter(y_)\n    title = f\"{t.title()} set data distribution\"\n    sep = \"=\" * len(title)\n    print(f\"{sep}\\n{title}\\n{sep}\")\n    print(\n        pd.DataFrame(dist.values(), index=dist.keys(), columns=[\"Count\"]).sort_index()\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is presented a random observation from each class from this dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_mnist_samples(X, y, title=None, n_subplots=None):\n    if not n_subplots:\n        n_subplots = [1, np.unique(y).shape[0]]\n    imshape = int(np.sqrt(X.shape[-1]))\n    fig, axes = plt.subplots(nrows=n_subplots[0], ncols=n_subplots[1], figsize=(20, 3))\n    if title:\n        fig.suptitle(title, fontsize=16)\n    for i, val in enumerate(np.unique(y)):\n        images = X[y == val]\n        img = images.iloc[np.random.randint(images.shape[0])]\n        if len(np.unique(y)) > 1:\n            axes[i].imshow(np.reshape(img.values, (imshape, imshape)), cmap=\"gray\")\n            axes[i].set_title(str(val))\n            axes[i].axis(\"off\")\n        else:\n            axes.imshow(np.reshape(img.values, (imshape, imshape)), cmap=\"gray\")\n            axes.set_title(str(val))\n            axes.axis(\"off\")\n\n\nplot_mnist_samples(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Generation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is presented the generation of new samples using the G-SMOTE\nalgorithm. The parameters `selection_strategy`, `deformation_factor` (d)\nand `truncation_factor` (t) vary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_disjoin(X1, y1, X2, y2):\n    \"\"\"returns rows that do not belong to one of the two datasets\"\"\"\n    if X1.shape[-1] != X2.shape[-1]:\n        raise ValueError(\"Both arrays must have equal shape on axis 1.\")\n\n    if X1.shape[0] > X2.shape[0]:\n        X_largest, y_largest, X_smallest, y_smallest = X1, y1, X2, y2\n    else:\n        X_largest, y_largest, X_smallest, y_smallest = X2, y2, X1, y1\n\n    intersecting_vals = np.in1d(X_largest, X_smallest).reshape(X_largest.shape)\n    disjoin_indexes = np.where(~np.all(intersecting_vals, axis=1))[0]\n    return X_largest.iloc[disjoin_indexes], y_largest.iloc[disjoin_indexes]\n\n\nfor strategy in [\"combined\", \"majority\", \"minority\"]:\n    X_gsmote_final = np.empty(shape=(0, X_train.shape[-1]))\n    y_gsmote_final = np.empty(shape=(0))\n    for d in [0, 0.5, 1]:\n        for t in [-1, 0, 1]:\n            gsmote_sampling = GeometricSMOTE(\n                k_neighbors=1,\n                deformation_factor=d,\n                truncation_factor=t,\n                n_jobs=-1,\n                selection_strategy=strategy,\n            ).fit_resample(X_train, y_train)\n            X_gsmote, _ = get_disjoin(\n                X_train, y_train, gsmote_sampling[0], gsmote_sampling[1]\n            )\n            X_gsmote_final = np.append(X_gsmote_final, X_gsmote, axis=0)\n            y_gsmote_final = np.append(\n                y_gsmote_final, np.array([f\"t={t}, d={d}\"] * X_gsmote.shape[0]), axis=0\n            )\n    plot_mnist_samples(\n        pd.DataFrame(X_gsmote_final),\n        pd.Series(y_gsmote_final),\n        f\"Generated Using G-SMOTE: {strategy}\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is presented the generation of new samples using the SMOTE\nalgorithm. Since there is only two instances with the label '1', `k_neighbors`\nis fixed to 1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smote_sampling = SMOTE(\n    k_neighbors=1,\n    n_jobs=-1,\n).fit_resample(X_train, y_train)\nX_smote, _ = get_disjoin(X_train, y_train, smote_sampling[0], smote_sampling[1])\nX_smote_final = X_smote[:10]\ny_smote_final = np.array([f\"Sample {n}\" for n in range(10)])\n\nplot_mnist_samples(\n    X_smote_final, y_smote_final, f\"Generated Using SMOTE, K neighbors: 1\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we train a Logistic Regression algorithm using the SMOTE and G-SMOTE\noversamling methods to predict the number in each picture of this imbalanced\n(binary) dataset. A total of 3 pipelines are fit:\n3 (SMOTE, G-SMOTE, No Oversampling) * 1 (LogisticRegression).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def model_fit(X_train, y_train, X_test, y_test):\n    classifier_dict = {\n        \"no_oversampling\": Pipeline(\n            [(\"none\", None), (\"lr\", LogisticRegression(solver=\"liblinear\"))]\n        ),\n        \"smote\": Pipeline(\n            [\n                (\"smote\", SMOTE(k_neighbors=1)),\n                (\"lr\", LogisticRegression(solver=\"liblinear\")),\n            ]\n        ),\n        \"gsmote\": Pipeline(\n            [\n                (\"gsmote\", GeometricSMOTE(k_neighbors=1)),\n                (\"lr\", LogisticRegression(solver=\"liblinear\")),\n            ]\n        ),\n    }\n    results = {}\n    for name, estimator in classifier_dict.items():\n        estimator.fit(X_train, y_train)\n        results[name] = estimator.score(X_test, y_test)\n    return pd.DataFrame(data=results.values(), index=results.keys(), columns=[\"score\"])\n\n\nresults = model_fit(X_train, y_train, X_test, y_test)\nprint(results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}