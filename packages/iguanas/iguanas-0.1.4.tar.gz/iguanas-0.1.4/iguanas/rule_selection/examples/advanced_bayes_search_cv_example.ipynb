{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0043af",
   "metadata": {},
   "source": [
    "# Advanced Bayes Search CV Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca415d6",
   "metadata": {},
   "source": [
    "This is a more advanced example of how the `BayesSearchCV` class can be applied - it's recommended that you first read through the simpler `bayes_search_cv_example`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466b454",
   "metadata": {},
   "source": [
    "The `BayesSearchCV` class is used to search for the set of hyperparameters that produce the best decision engine performance for a given Iguanas Pipeline, whilst also reducing the likelihood of overfitting.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "* Generate k-fold stratified cross validation datasets. \n",
    "* For each of the training and validation datasets:\n",
    "    * Fit the pipeline on the training set using a set of parameters chosen by the Bayesian Optimiser from a given set of ranges.\n",
    "    * Apply the pipeline to the validation set to return a prediction.\n",
    "    * Use the provided `scorer` to calculate the score of the prediction.\n",
    "* Return the parameter set which generated the highest mean overall score across the validation datasets.\n",
    "\n",
    "In this example, we'll consider the following more advanced workflow (compared to the standard `bayes_search_cv_example` notebook), which considers the generation of a Rules-Based System for a credit card fraud transaction use case:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e904a",
   "metadata": {},
   "source": [
    "<center><img src=\"images/complex_example.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8775fbd",
   "metadata": {},
   "source": [
    "Here, we have a fraud detection use case, and we're aiming to create two distinct rule sets - one for flagging fraudulent behaviour (which we'll refer to as our **Reject** rule set); one for flagging good behaviour (which we'll refer to as our **Approve** rule set). Each of these rule sets will be comprised of a generated rule set and an existing rule set. We'll optimise and filter these two rule sets separately, then combine and feed them into the decision engine optimiser. **Note:** we optimise the generated rules as they'll be created using the `RuleGeneratorDT` class, which generates rules from the branches of decision trees - these split based on gini or entropy - so we can further optimise them for a specific metric. \n",
    "\n",
    "**The decision engine will have the following constraint:** for a given transaction, if any approve rules fire it will be approved; else, if any reject rules fire it will be rejected; else, it will be approved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b1e38",
   "metadata": {},
   "source": [
    "We'll use the `BayesSearchCV` class to optimise the hyperparameters of the steps in this workflow, **ensuring that we maximise the revenue for our decision engine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245e470",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3050e",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bba7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iguanas.rule_generation import RuleGeneratorDT\n",
    "from iguanas.rule_selection import SimpleFilter, CorrelatedFilter, GreedyFilter, BayesSearchCV\n",
    "from iguanas.metrics import FScore, Precision, Revenue, JaccardSimilarity\n",
    "from iguanas.rbs import RBSOptimiser, RBSPipeline\n",
    "from iguanas.correlation_reduction import AgglomerativeClusteringReducer\n",
    "from iguanas.pipeline import LinearPipeline, ParallelPipeline\n",
    "from iguanas.pipeline.class_accessor import ClassAccessor\n",
    "from iguanas.space import UniformFloat, UniformInteger, Choice\n",
    "from iguanas.rules import Rules\n",
    "from iguanas.rule_optimisation import BayesianOptimiser\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49cc53",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf822bd",
   "metadata": {},
   "source": [
    "Let's read in the [credit card fraud dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) from Kaggle.\n",
    "\n",
    "**Note:** this data has been altered to include some null values in the `V1` column. This is to simulate unprocessed data (the dataset on Kaggle has been processed using PCA, so there are no null values). It has also been randomly sampled to 10% of its original number of records, to reduce the file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6d7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Class'\n",
    "time_col = 'Time'\n",
    "amt_col = 'Amount'\n",
    "# Ready in data\n",
    "df = pd.read_csv('dummy_data/creditcard.csv')\n",
    "# Sort data by time ascending\n",
    "df.sort_values(time_col, ascending=True)\n",
    "# Create X and y dataframes\n",
    "X = df.drop([target_col, time_col], axis=1)\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b516610",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591bfa6",
   "metadata": {},
   "source": [
    "To calculate the **Revenue**, we need the monetary amount of each transaction - we'll use these later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da13bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "amts_train = X_train_raw[amt_col]\n",
    "amts_test = X_test_raw[amt_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aca1c7",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994850f",
   "metadata": {},
   "source": [
    "Let's impute the null values with the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f1a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train_raw),\n",
    "    columns=X_train_raw.columns,\n",
    "    index=X_train_raw.index\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    imputer.transform(X_test_raw),\n",
    "    columns=X_test_raw.columns,\n",
    "    index=X_test_raw.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baff9795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nulls have been imputed\n",
    "X_train.isna().sum().sum(), X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740675e7",
   "metadata": {},
   "source": [
    "### Existing rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b189d",
   "metadata": {},
   "source": [
    "Let's also assume we have the following existing rules, stored in the standard Iguanas string format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a3374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_rule_strings = {\n",
    "    \"ExistingReject1\": \"((X['V1']<0)|(X['V1'].isna()))&(X['V3']<1)\",\n",
    "    \"ExistingReject2\": \"(X['V2']>3)\",\n",
    "}\n",
    "approve_rule_strings = {\n",
    "    \"ExistingApprove1\": \"(X['V1']>0)&(X['V3']>1)\",\n",
    "    \"ExistingApprove2\": \"(X['V2']<3)\",\n",
    "    \"ExistingApprove3\": \"(X['V4']<3)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4f472",
   "metadata": {},
   "source": [
    "We can create a `Rules` class for each of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14487c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_rules = Rules(rule_strings=reject_rule_strings)\n",
    "approve_rules = Rules(rule_strings=approve_rule_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26786ef",
   "metadata": {},
   "source": [
    "Then convert them to the standard Iguanas lambda expression format (we'll need this for the optimisation step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e40dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_rule_lambdas = reject_rules.as_rule_lambdas(\n",
    "    as_numpy=False, \n",
    "    with_kwargs=True\n",
    ")\n",
    "approve_rule_lambdas = approve_rules.as_rule_lambdas(\n",
    "    as_numpy=False, \n",
    "    with_kwargs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370e12e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb1f90",
   "metadata": {},
   "source": [
    "## Set up pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90b23d",
   "metadata": {},
   "source": [
    "Before we can apply the `BayesSearchCV` class, we need to set up our pipeline. To create the workflow shown at the beginning of the notebook, we must use a combination of `LinearPipeline` and `ParallelPipeline` classes as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aacd64b",
   "metadata": {},
   "source": [
    "![title](images/complex_example_setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db9207",
   "metadata": {},
   "source": [
    "Let's begin building the **Reject *LinearPipeline***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518a19f",
   "metadata": {},
   "source": [
    "### Reject *LinearPipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702d3c4",
   "metadata": {},
   "source": [
    "Let's first instantiate the classes that we'll use in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c8e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "f1 = FScore(beta=1)\n",
    "# Precision\n",
    "p = Precision()\n",
    "    \n",
    "# Rule generation\n",
    "reject_gen = RuleGeneratorDT(\n",
    "    metric=f1.fit,\n",
    "    n_total_conditions=2,\n",
    "    tree_ensemble=RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=0\n",
    "    ),\n",
    "    target_feat_corr_types='Infer',\n",
    "    rule_name_prefix='Reject' # Set this so generated reject rules distinguishable from approve rules\n",
    ")\n",
    "\n",
    "# Rule optimisation (for generated rules)\n",
    "reject_gen_opt = BayesianOptimiser(\n",
    "    rule_lambdas=ClassAccessor(\n",
    "        class_tag='reject_gen',\n",
    "        class_attribute='rule_lambdas'\n",
    "    ),\n",
    "    lambda_kwargs=ClassAccessor(\n",
    "        class_tag='reject_gen',\n",
    "        class_attribute='lambda_kwargs'\n",
    "    ),\n",
    "    metric=f1.fit,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Rule optimisation (for existing rules)\n",
    "reject_opt = BayesianOptimiser(\n",
    "    rule_lambdas=reject_rule_lambdas,\n",
    "    lambda_kwargs=reject_rules.lambda_kwargs,\n",
    "    metric=f1.fit,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Rule filter (performance-based)\n",
    "reject_sf = SimpleFilter(\n",
    "    threshold=0.1, \n",
    "    operator='>=', \n",
    "    metric=f1.fit\n",
    ")\n",
    "\n",
    "# Rule filter (correlation-based)\n",
    "js = JaccardSimilarity()\n",
    "reject_cf = CorrelatedFilter(\n",
    "    correlation_reduction_class=AgglomerativeClusteringReducer(\n",
    "        threshold=0.9, \n",
    "        strategy='top_down', \n",
    "        similarity_function=js.fit, \n",
    "        metric=f1.fit\n",
    "    ), \n",
    "    rules=ClassAccessor(\n",
    "        class_tag='reject_gen',\n",
    "        class_attribute='rules'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bca40",
   "metadata": {},
   "source": [
    "Now we can create our **Reject Rule Generation *LinearPipeline***. Note that we pass the tag for the optimisation of the generated rules to the `use_init_data` parameter, so that the feature set is passed to the `BayesianOptimiser` class, rather than the output from the `RuleGeneratorDT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7c21486",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_gen_lp = LinearPipeline(\n",
    "    steps = [\n",
    "        ('reject_gen', reject_gen),\n",
    "        ('reject_gen_opt', reject_gen_opt),\n",
    "    ],\n",
    "    use_init_data=['reject_gen_opt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79c98a",
   "metadata": {},
   "source": [
    "And then our **Reject *ParallelPipeline*** (noting that one of the steps in this pipeline is the **Reject Rule Generation *LinearPipeline*** created above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43366ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_pp = ParallelPipeline(\n",
    "    steps = [\n",
    "        ('reject_gen_lp', reject_gen_lp),\n",
    "        ('reject_opt', reject_opt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57731983",
   "metadata": {},
   "source": [
    "And then finally, our **Reject *LinearPipeline***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78718814",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_lp = LinearPipeline(\n",
    "    steps = [\n",
    "        ('reject_pp', reject_pp),\n",
    "        ('reject_sf', reject_sf),\n",
    "        ('reject_cf', reject_cf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747891f",
   "metadata": {},
   "source": [
    "Now we can do the same for the **Approve *LinearPipeline***:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c5465",
   "metadata": {},
   "source": [
    "### Approve *LinearPipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f117c",
   "metadata": {},
   "source": [
    "Let's first instantiate the classes that we'll use in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f7643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule generation\n",
    "approve_gen = RuleGeneratorDT(\n",
    "    metric=f1.fit,\n",
    "    n_total_conditions=2,\n",
    "    tree_ensemble=RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=0\n",
    "    ),\n",
    "    target_feat_corr_types='Infer',\n",
    "    rule_name_prefix='Approve' # Set this so generated reject rules distinguishable from approve rules\n",
    ")\n",
    "\n",
    "# Rule optimisation (for generated rules)\n",
    "approve_gen_opt = BayesianOptimiser(\n",
    "    rule_lambdas=ClassAccessor(\n",
    "        class_tag='approve_gen',\n",
    "        class_attribute='rule_lambdas'\n",
    "    ),\n",
    "    lambda_kwargs=ClassAccessor(\n",
    "        class_tag='approve_gen',\n",
    "        class_attribute='lambda_kwargs'\n",
    "    ),\n",
    "    metric=f1.fit,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Rule optimisation (for existing rules)\n",
    "approve_opt = BayesianOptimiser(\n",
    "    rule_lambdas=approve_rule_lambdas,\n",
    "    lambda_kwargs=approve_rules.lambda_kwargs,\n",
    "    metric=f1.fit,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# Rule filter (performance-based)\n",
    "approve_sf = SimpleFilter(\n",
    "    threshold=0.1, \n",
    "    operator='>=', \n",
    "    metric=f1.fit\n",
    ")\n",
    "\n",
    "# Rule filter (correlation-based)\n",
    "js = JaccardSimilarity()\n",
    "approve_cf = CorrelatedFilter(\n",
    "    correlation_reduction_class=AgglomerativeClusteringReducer(\n",
    "        threshold=0.9, \n",
    "        strategy='top_down', \n",
    "        similarity_function=js.fit, \n",
    "        metric=f1.fit\n",
    "    ),\n",
    "    rules=ClassAccessor(\n",
    "        class_tag='approve_gen',\n",
    "        class_attribute='rules'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6ff6d",
   "metadata": {},
   "source": [
    "Now we can create our **Approve Rule Generation *LinearPipeline***. Note that we pass the tag for the optimisation of the generated rules to the `use_init_data` parameter, so that the feature set is passed to the `BayesianOptimiser` class, rather than the output from the `RuleGeneratorDT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff787dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_gen_lp = LinearPipeline(\n",
    "    steps = [\n",
    "        ('approve_gen', approve_gen),\n",
    "        ('approve_gen_opt', approve_gen_opt),\n",
    "    ],\n",
    "    use_init_data=['approve_gen_opt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4a116",
   "metadata": {},
   "source": [
    "And then our **Approve *ParallelPipeline*** (noting that one of the steps in this pipeline is the **Approve Rule Generation *LinearPipeline*** created above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d9e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_pp = ParallelPipeline(\n",
    "    steps = [\n",
    "        ('approve_gen_lp', approve_gen_lp),\n",
    "        ('approve_opt', approve_opt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bba728",
   "metadata": {},
   "source": [
    "And then finally, our **Approve *LinearPipeline***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "approve_lp = LinearPipeline(\n",
    "    steps = [\n",
    "        ('approve_pp', approve_pp),\n",
    "        ('approve_sf', approve_sf),\n",
    "        ('approve_cf', approve_cf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5c0d0",
   "metadata": {},
   "source": [
    "Now we can move on to constructing the **Overall Pipelines:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bd29e",
   "metadata": {},
   "source": [
    "### Overall Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f648069",
   "metadata": {},
   "source": [
    "First, we'll construct our **Overall *ParallelPipeline*** using the **Reject *LinearPipeline*** and **Approve *LinearPipeline***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5643ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pp = ParallelPipeline(\n",
    "    steps = [\n",
    "        ('reject_lp', reject_lp),\n",
    "        ('approve_lp', approve_lp)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3007c",
   "metadata": {},
   "source": [
    "Now we can instantiate the decision engine optimiser. Since we have a constraint on the decision engine (if any approve rules fire, approve the transaction; else if any reject rules fire, reject the transaction; else approve the transaction), we pass the rules remaining after the filtering stages to the relevant elements in the `config` parameter of the `RBSPipeline` class, using the `ClassAccessor` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cdd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision engine optimisation metric\n",
    "opt_metric = Revenue(\n",
    "    y_type='Fraud',\n",
    "    chargeback_multiplier=3\n",
    ")\n",
    "\n",
    "# Decision engine (to be optimised)\n",
    "rbs_pipeline = RBSPipeline(\n",
    "    config=[\n",
    "        [\n",
    "            0, ClassAccessor( # If any approve rules fire, approve\n",
    "                class_tag='approve_cf', \n",
    "                class_attribute='rules_to_keep'\n",
    "            ),\n",
    "        ],\n",
    "        [\n",
    "            1, ClassAccessor( # Else if any reject rules fire, reject\n",
    "                class_tag='reject_cf', \n",
    "                class_attribute='rules_to_keep'\n",
    "            )\n",
    "        ],        \n",
    "    ],\n",
    "    final_decision=0 # Else approve\n",
    ")\n",
    "\n",
    "# Decision engine optimiser\n",
    "rbs_optimiser = RBSOptimiser(\n",
    "    pipeline=rbs_pipeline,\n",
    "    metric=opt_metric.fit,     \n",
    "    rules=ClassAccessor(\n",
    "        class_tag='overall_pp',\n",
    "        class_attribute='rules'\n",
    "    ),\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27910e30",
   "metadata": {},
   "source": [
    "Finally, we can instantiate our **Overall *LinearPipeline***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f206a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_lp = LinearPipeline(\n",
    "    steps=[\n",
    "        ('overall_pp', overall_pp),\n",
    "        ('rbs_optimiser', rbs_optimiser)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448d0cc",
   "metadata": {},
   "source": [
    "## Define the search space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16442336",
   "metadata": {},
   "source": [
    "Now we need to define the search space for each of the relevant parameters of our pipeline. **Note:** this example does not search across all hyperparameters - you should define your own search spaces based on your use case.\n",
    "\n",
    "To do this, we create a dictionary, where each key corresponds to the tag used for the relevant pipeline step. Each value should be a dictionary of the parameters (keys) and their search spaces (values). Search spaces should be defined using the classes in the `iguanas.space` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb1a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional FScores\n",
    "f0dot5 = FScore(beta=0.5)\n",
    "f0dot25 = FScore(beta=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0590a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'reject_gen': {\n",
    "        'n_total_conditions': UniformInteger(2, 7),\n",
    "    },\n",
    "    'reject_gen_opt': {\n",
    "        'metric': Choice([f0dot25.fit, f0dot5.fit, f1.fit]),\n",
    "    },\n",
    "    'reject_sf': {\n",
    "        'threshold': UniformFloat(0, 1),\n",
    "    },\n",
    "    'reject_cf': {\n",
    "        'correlation_reduction_class': Choice(\n",
    "            [\n",
    "                AgglomerativeClusteringReducer(\n",
    "                    threshold=0.9, \n",
    "                    strategy='top_down', \n",
    "                    similarity_function=js.fit, \n",
    "                    metric=f1.fit                    \n",
    "                ),\n",
    "                AgglomerativeClusteringReducer(\n",
    "                    threshold=0.95, \n",
    "                    strategy='top_down', \n",
    "                    similarity_function=js.fit, \n",
    "                    metric=f1.fit                    \n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    },    \n",
    "    'approve_gen': {\n",
    "        'n_total_conditions': UniformInteger(2, 7),\n",
    "    },\n",
    "    'approve_gen_opt': {\n",
    "        'metric': Choice([f0dot25.fit, f0dot5.fit, f1.fit]),\n",
    "    },\n",
    "    'approve_sf': {\n",
    "        'threshold': UniformFloat(0, 1),\n",
    "    },\n",
    "    'approve_cf': {\n",
    "        'correlation_reduction_class': Choice(\n",
    "            [\n",
    "                AgglomerativeClusteringReducer(\n",
    "                    threshold=0.9, \n",
    "                    strategy='top_down', \n",
    "                    similarity_function=js.fit, \n",
    "                    metric=f1.fit                    \n",
    "                ),\n",
    "                AgglomerativeClusteringReducer(\n",
    "                    threshold=0.95, \n",
    "                    strategy='top_down', \n",
    "                    similarity_function=js.fit, \n",
    "                    metric=f1.fit                    \n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84f1b5",
   "metadata": {},
   "source": [
    "## Optimise the pipeline hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144ece",
   "metadata": {},
   "source": [
    "Now that we have our pipeline and search spaces defined, we can instantiate the `BayesSearchCV` class. We'll split our data into 3 cross-validation datasets and try 10 different parameter sets.\n",
    "\n",
    "**Note:** since we're using the `Revenue` as the scoring metric for the `BayesSearchCV` class, we need to set the `sample_weight_in_val` parameter to `True`. This ensures that the `sample_weight` passed to the final step in the pipeline is used when applying the `metric` function to the prediction of each validation set (for `Revenue`, the `sample_weight` corresponds to the monetary amount of each transaction, which is required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d438fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BayesSearchCV(\n",
    "    pipeline=overall_lp, \n",
    "    search_spaces=search_spaces, \n",
    "    metric=opt_metric.fit, # Use the same metric as the RBSOptimiser\n",
    "    cv=3, \n",
    "    n_iter=10,\n",
    "    num_cores=3,\n",
    "    error_score=0,\n",
    "    verbose=1,\n",
    "    sample_weight_in_val=True # Set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21fef5",
   "metadata": {},
   "source": [
    "Finally, we can run the `fit` method to optimise the hyperparameters of the pipeline. \n",
    "\n",
    "**Note the following:** \n",
    "\n",
    "* The existing rules contain conditions that rely on unprocessed data (in this case, there are conditions that check for nulls). So for the rule optimisation steps, we must use the unprocessed training data `X_train_raw`; for the rule generation steps, we must use the processed training data `X_train`.\n",
    "* Since we're generating and optimising rules that flag both positive and negative cases (i.e. reject and approve rules in this example), we need to specify what the target is in each case. For the reject rules, we can just use `y_train`, however for the approve rules, we need to flip `y_train` (so that the rule generator and rule optimisers target the negative cases).\n",
    "* We need the `amts_train` to be passed to the `sample_weight` parameter of the `RBSOptimiser`, as we're optimising the decision engine for the `Revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8eb906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimising pipeline parameters ---\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:13<00:00,  7.37s/trial, best loss: -555025.6433333332]\n",
      "--- Refitting on entire dataset with best pipeline ---\n"
     ]
    }
   ],
   "source": [
    "bs.fit(\n",
    "    X={\n",
    "        'reject_lp': X_train, # Use processed features for rule generation\n",
    "        'reject_opt': X_train_raw, # Use raw features for optimising existing rules\n",
    "        'approve_lp': X_train, # Use processed features for rule generation\n",
    "        'approve_opt': X_train_raw # Use raw features for optimising existing rules\n",
    "    }, \n",
    "    y={\n",
    "        'reject_lp': y_train, # Use target for Reject LinearPipeline\n",
    "        'approve_lp': 1-y_train, # Flip target for Approve LinearPipeline\n",
    "        'rbs_optimiser': y_train # Use target for RBSOptimiser\n",
    "    },\n",
    "    sample_weight={\n",
    "        'reject_lp': None, # No sample_weight for Reject LinearPipeline\n",
    "        'approve_lp': None, # No sample_weight for Approve LinearPipeline\n",
    "        'rbs_optimiser': amts_train # sample_weight for RBSOptimiser\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e6a8d",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4f38a",
   "metadata": {},
   "source": [
    "The `fit` method doesn't return anything. See the `Attributes` section in the class docstring for a description of each attribute generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eab399ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555025.6433333332"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0604241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)},\n",
       " 'approve_gen': {'n_total_conditions': 7.0},\n",
       " 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.5>},\n",
       " 'approve_sf': {'threshold': 0.43381170823234194},\n",
       " 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.95, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)},\n",
       " 'reject_gen': {'n_total_conditions': 5.0},\n",
       " 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.25>},\n",
       " 'reject_sf': {'threshold': 0.5309641649521473}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c77218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6ba02b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Params</th>\n",
       "      <th>approve_cf__correlation_reduction_class</th>\n",
       "      <th>approve_gen__n_total_conditions</th>\n",
       "      <th>approve_gen_opt__metric</th>\n",
       "      <th>approve_sf__threshold</th>\n",
       "      <th>reject_cf__correlation_reduction_class</th>\n",
       "      <th>reject_gen__n_total_conditions</th>\n",
       "      <th>reject_gen_opt__metric</th>\n",
       "      <th>reject_sf__threshold</th>\n",
       "      <th>FoldIdx</th>\n",
       "      <th>Scores</th>\n",
       "      <th>MeanScore</th>\n",
       "      <th>StdDevScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'approve_cf': {'correlation_reduction_class':...</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.9, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0.5&gt;</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0...</td>\n",
       "      <td>0.530964</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[572829.7, 569910.5599999999, 522336.67000000004]</td>\n",
       "      <td>555025.643333</td>\n",
       "      <td>23145.295818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'approve_cf': {'correlation_reduction_class':...</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0...</td>\n",
       "      <td>0.457207</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.9, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0...</td>\n",
       "      <td>0.528692</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[573229.7, 555044.7199999999, 535382.05]</td>\n",
       "      <td>554552.156667</td>\n",
       "      <td>15455.163465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'approve_cf': {'correlation_reduction_class':...</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0.5&gt;</td>\n",
       "      <td>0.195596</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.9, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=1&gt;</td>\n",
       "      <td>0.486047</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[572817.9400000001, 555595.08, 524511.97]</td>\n",
       "      <td>550974.996667</td>\n",
       "      <td>19989.589989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'approve_cf': {'correlation_reduction_class':...</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0...</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=1&gt;</td>\n",
       "      <td>0.510489</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[572121.0199999999, 538455.7999999999, 535382.05]</td>\n",
       "      <td>548652.956667</td>\n",
       "      <td>16641.804434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'approve_cf': {'correlation_reduction_class':...</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=0...</td>\n",
       "      <td>0.933435</td>\n",
       "      <td>AgglomerativeClusteringReducer(threshold=0.95,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;bound method FScore.fit of FScore with beta=1&gt;</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[573019.7, 541266.7200000001, 528778.51]</td>\n",
       "      <td>547688.310000</td>\n",
       "      <td>18623.432135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Params  \\\n",
       "1  {'approve_cf': {'correlation_reduction_class':...   \n",
       "3  {'approve_cf': {'correlation_reduction_class':...   \n",
       "0  {'approve_cf': {'correlation_reduction_class':...   \n",
       "8  {'approve_cf': {'correlation_reduction_class':...   \n",
       "9  {'approve_cf': {'correlation_reduction_class':...   \n",
       "\n",
       "             approve_cf__correlation_reduction_class  \\\n",
       "1  AgglomerativeClusteringReducer(threshold=0.9, ...   \n",
       "3  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "0  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "8  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "9  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "\n",
       "   approve_gen__n_total_conditions  \\\n",
       "1                              7.0   \n",
       "3                              2.0   \n",
       "0                              3.0   \n",
       "8                              7.0   \n",
       "9                              6.0   \n",
       "\n",
       "                             approve_gen_opt__metric  approve_sf__threshold  \\\n",
       "1  <bound method FScore.fit of FScore with beta=0.5>               0.433812   \n",
       "3  <bound method FScore.fit of FScore with beta=0...               0.457207   \n",
       "0  <bound method FScore.fit of FScore with beta=0.5>               0.195596   \n",
       "8  <bound method FScore.fit of FScore with beta=0...               0.027295   \n",
       "9  <bound method FScore.fit of FScore with beta=0...               0.933435   \n",
       "\n",
       "              reject_cf__correlation_reduction_class  \\\n",
       "1  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "3  AgglomerativeClusteringReducer(threshold=0.9, ...   \n",
       "0  AgglomerativeClusteringReducer(threshold=0.9, ...   \n",
       "8  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "9  AgglomerativeClusteringReducer(threshold=0.95,...   \n",
       "\n",
       "   reject_gen__n_total_conditions  \\\n",
       "1                             5.0   \n",
       "3                             4.0   \n",
       "0                             4.0   \n",
       "8                             3.0   \n",
       "9                             5.0   \n",
       "\n",
       "                              reject_gen_opt__metric  reject_sf__threshold  \\\n",
       "1  <bound method FScore.fit of FScore with beta=0...              0.530964   \n",
       "3  <bound method FScore.fit of FScore with beta=0...              0.528692   \n",
       "0    <bound method FScore.fit of FScore with beta=1>              0.486047   \n",
       "8    <bound method FScore.fit of FScore with beta=1>              0.510489   \n",
       "9    <bound method FScore.fit of FScore with beta=1>              0.092054   \n",
       "\n",
       "     FoldIdx                                             Scores  \\\n",
       "1  [0, 1, 2]  [572829.7, 569910.5599999999, 522336.67000000004]   \n",
       "3  [0, 1, 2]           [573229.7, 555044.7199999999, 535382.05]   \n",
       "0  [0, 1, 2]          [572817.9400000001, 555595.08, 524511.97]   \n",
       "8  [0, 1, 2]  [572121.0199999999, 538455.7999999999, 535382.05]   \n",
       "9  [0, 1, 2]           [573019.7, 541266.7200000001, 528778.51]   \n",
       "\n",
       "       MeanScore   StdDevScore  \n",
       "1  555025.643333  23145.295818  \n",
       "3  554552.156667  15455.163465  \n",
       "0  550974.996667  19989.589989  \n",
       "8  548652.956667  16641.804434  \n",
       "9  547688.310000  18623.432135  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fee79c",
   "metadata": {},
   "source": [
    "To see the final optimised decision engine configuration and rule set, we first return the parameters of the trained pipeline (stored in the attribute `pipeline_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b77ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = bs.pipeline_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c01f6",
   "metadata": {},
   "source": [
    "Then, to see the final optimised decision engine configuration, we filter to the `config` parameter of the `rbs_optimiser` step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a3436e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, ['Approve_44', 'Approve_73', 'Approve_40']],\n",
       " [1,\n",
       "  ['Reject_15',\n",
       "   'Reject_18',\n",
       "   'Reject_4',\n",
       "   'Reject_17',\n",
       "   'Reject_21',\n",
       "   'Reject_2',\n",
       "   'Reject_29',\n",
       "   'Reject_19']]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_config = pipeline_params['rbs_optimiser']['config']\n",
    "final_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f1620",
   "metadata": {},
   "source": [
    "This shows us which rules should be used for the approval step (decision `0`) and which rules should be used for the rejection step (decision `1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3088bd",
   "metadata": {},
   "source": [
    "To see the logic of our final set of rules, we filter to the `rules` parameter of the `rbs_optimiser` step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e275fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rules = bs.pipeline_.get_params()['rbs_optimiser']['rules']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb6bb4",
   "metadata": {},
   "source": [
    "Then extract the `rule_strings` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69871ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reject_2': \"(X['V1']<=1.57711)&(X['V14']<=-5.9433)&(X['V26']>-0.27216)\",\n",
       " 'Reject_4': \"(X['V10']<=-2.70569)&(X['V11']>3.26894)&(X['V19']>-3.50737)\",\n",
       " 'Reject_15': \"(X['V12']<=-2.1202)&(X['V14']<=-4.64098)\",\n",
       " 'Reject_17': \"(X['V12']<=-4.43659)\",\n",
       " 'Reject_18': \"(X['V12']<=-4.43715)\",\n",
       " 'Reject_19': \"(X['V12']<=-4.59928)\",\n",
       " 'Reject_21': \"(X['V14']<=-11.33548)&(X['V17']<=-2.69333)&(X['V27']>1.1957)\",\n",
       " 'Reject_29': \"(X['V17']<=-2.18248)&(X['V27']>-4.29354)\",\n",
       " 'Approve_40': \"(X['V11']<=3.35091)&(X['V12']>-3.67614)&(X['V13']>0.43179)&(X['V17']>-2.69333)\",\n",
       " 'Approve_44': \"(X['V11']<=3.35091)&(X['V12']>-4.59928)&(X['V16']>-2.1745)&(X['V17']>-2.69333)&(X['V19']<=-1.48536)\",\n",
       " 'Approve_73': \"(X['V17']>-2.18248)&(X['V19']<=-3.52538)\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rules.rule_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf9523",
   "metadata": {},
   "source": [
    "## Apply the optimised pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37268ca",
   "metadata": {},
   "source": [
    "We can apply our optimised pipeline to a new data set and make a prediction using the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d84d15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = bs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6b858",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daef4cf",
   "metadata": {},
   "source": [
    "The `predict` method returns the prediction generated by class in the final step of the pipeline - in this case, the `RBSOptimiser`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "540493b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17855    0\n",
       "23775    0\n",
       "18629    0\n",
       "12843    0\n",
       "18084    0\n",
       "        ..\n",
       "2223     0\n",
       "10168    0\n",
       "23823    0\n",
       "16583    0\n",
       "22478    0\n",
       "Length: 9399, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3c446",
   "metadata": {},
   "source": [
    "We can now calculate the **Revenue** of our optimised pipeline using the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a6a478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_opt = opt_metric.fit(\n",
    "    y_preds=y_pred_test,\n",
    "    y_true=y_test,\n",
    "    sample_weight=amts_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf42412",
   "metadata": {},
   "source": [
    "Comparing this to our original, unoptimised pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "042493b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_lp.fit(\n",
    "    X={\n",
    "        'reject_gen_lp': X_train,\n",
    "        'reject_opt': X_train_raw,\n",
    "        'approve_gen_lp': X_train,\n",
    "        'approve_opt': X_train_raw    \n",
    "    }, \n",
    "    y={\n",
    "        'reject_lp': y_train,\n",
    "        'approve_lp': 1-y_train,\n",
    "        'rbs_optimiser': y_train\n",
    "    },\n",
    "    sample_weight={\n",
    "        'reject_lp': None,\n",
    "        'approve_lp': None,\n",
    "        'rbs_optimiser': y_train        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ad6ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_init = overall_lp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16b2f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_init = opt_metric.fit(\n",
    "    y_preds=y_pred_test_init,\n",
    "    y_true=y_test,\n",
    "    sample_weight=amts_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb277364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue of original, unoptimised pipeline: $775698\n",
      "Revenue of optimised pipeline: $856076\n",
      "Absolute improvement in Revenue: $80379\n",
      "Percentage improvement in Revenue: 10.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlaidler/Documents/Iguanas/iguanas/pipeline/parallel_pipeline.py:151: NoRulesWarning: No rules remain in step `reject_lp` as it raised the following error: \"`X` has been reduced to zero columns after the `reject_sf` step in the pipeline.\"\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/rule_selection/bayes_search_cv.py:518: NoRulesWarning: No rules remaining for: Pipeline parameter set = {'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'approve_gen': {'n_total_conditions': 3.0}, 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=1>}, 'approve_sf': {'threshold': 0.48617287843841694}, 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.95, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'reject_gen': {'n_total_conditions': 4.0}, 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=1>}, 'reject_sf': {'threshold': 0.8381663825532006}}; Fold index = 2. The metric score for this parameter set & fold will be set to 0\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/pipeline/parallel_pipeline.py:151: NoRulesWarning: No rules remain in step `reject_lp` as it raised the following error: \"`X` has been reduced to zero columns after the `reject_sf` step in the pipeline.\"\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/rule_selection/bayes_search_cv.py:518: NoRulesWarning: No rules remaining for: Pipeline parameter set = {'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'approve_gen': {'n_total_conditions': 6.0}, 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.25>}, 'approve_sf': {'threshold': 0.18427923771610466}, 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'reject_gen': {'n_total_conditions': 3.0}, 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.5>}, 'reject_sf': {'threshold': 0.9671312248842996}}; Fold index = 1. The metric score for this parameter set & fold will be set to 0\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/pipeline/parallel_pipeline.py:151: NoRulesWarning: No rules remain in step `reject_lp` as it raised the following error: \"`X` has been reduced to zero columns after the `reject_cf` step in the pipeline.\"\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/rule_selection/bayes_search_cv.py:518: NoRulesWarning: No rules remaining for: Pipeline parameter set = {'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'approve_gen': {'n_total_conditions': 3.0}, 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=1>}, 'approve_sf': {'threshold': 0.48617287843841694}, 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.95, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'reject_gen': {'n_total_conditions': 4.0}, 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=1>}, 'reject_sf': {'threshold': 0.8381663825532006}}; Fold index = 1. The metric score for this parameter set & fold will be set to 0\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/pipeline/parallel_pipeline.py:151: NoRulesWarning: No rules remain in step `reject_lp` as it raised the following error: \"`X` has been reduced to zero columns after the `reject_sf` step in the pipeline.\"\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/rule_selection/bayes_search_cv.py:518: NoRulesWarning: No rules remaining for: Pipeline parameter set = {'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'approve_gen': {'n_total_conditions': 6.0}, 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.25>}, 'approve_sf': {'threshold': 0.18427923771610466}, 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'reject_gen': {'n_total_conditions': 3.0}, 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.5>}, 'reject_sf': {'threshold': 0.9671312248842996}}; Fold index = 0. The metric score for this parameter set & fold will be set to 0\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/pipeline/parallel_pipeline.py:151: NoRulesWarning: No rules remain in step `reject_lp` as it raised the following error: \"`X` has been reduced to zero columns after the `reject_sf` step in the pipeline.\"\n",
      "  warnings.warn(\n",
      "/Users/jlaidler/Documents/Iguanas/iguanas/rule_selection/bayes_search_cv.py:518: NoRulesWarning: No rules remaining for: Pipeline parameter set = {'approve_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'approve_gen': {'n_total_conditions': 6.0}, 'approve_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.25>}, 'approve_sf': {'threshold': 0.18427923771610466}, 'reject_cf': {'correlation_reduction_class': AgglomerativeClusteringReducer(threshold=0.9, strategy=top_down, similarity_function=<bound method JaccardSimilarity.fit of JaccardSimilarity>, metric=<bound method FScore.fit of FScore with beta=1>, print_clustermap=False)}, 'reject_gen': {'n_total_conditions': 3.0}, 'reject_gen_opt': {'metric': <bound method FScore.fit of FScore with beta=0.5>}, 'reject_sf': {'threshold': 0.9671312248842996}}; Fold index = 2. The metric score for this parameter set & fold will be set to 0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'Revenue of original, unoptimised pipeline: ${round(rev_init)}')\n",
    "print(f'Revenue of optimised pipeline: ${round(rev_opt)}')\n",
    "print(f'Absolute improvement in Revenue: ${round(rev_opt-rev_init)}')\n",
    "print(f'Percentage improvement in Revenue: {round(100*(rev_opt-rev_init)/rev_init, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba478f2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6685254d60582b062d48300206fb618b9ca57bf077cfb82364254cb725cf2213"
  },
  "kernelspec": {
   "display_name": "iguanas_dev",
   "language": "python",
   "name": "iguanas_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
